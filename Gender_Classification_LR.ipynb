{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DylanCTY/TextAnalyticsProject_Group5/blob/main/Gender_Classification_LR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFpRdjEm5lcc"
      },
      "outputs": [],
      "source": [
        "!unzip Gender.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#use  pydub library to provides a simple interface to work with audio files\n",
        "!pip install pydub"
      ],
      "metadata": {
        "id": "im47Nlu--B3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wA7KlTYD_Q8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Function to convert .m4a files to .wav format\n",
        "def convert_m4a_to_wav(input_folder, output_folder):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Loop through each file in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(\".m4a\"):\n",
        "            # Construct input and output file paths\n",
        "            input_file = os.path.join(input_folder, filename)\n",
        "            output_file = os.path.join(output_folder, os.path.splitext(filename)[0] + \".wav\")\n",
        "\n",
        "            # Load the .m4a file\n",
        "            audio = AudioSegment.from_file(input_file, format=\"m4a\")\n",
        "\n",
        "            # Export the audio to .wav format\n",
        "            audio.export(output_file, format=\"wav\")\n",
        "\n",
        "# Input folder containing .m4a files\n",
        "input_folder = \"Gender\"\n",
        "\n",
        "# Output folder where .wav files will be saved\n",
        "output_folder = \"Gender_WAV\"\n",
        "\n",
        "# Convert .m4a files to .wav format\n",
        "convert_m4a_to_wav(input_folder, output_folder)\n",
        "\n",
        "print(\"Conversion completed successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiU2dNuK-FhI",
        "outputId": "8c9c03f3-9bbe-452e-a7f3-d8672c79043e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversion completed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing:\n",
        "Resampling the Audio:\n",
        "Resampling is done to ensure that all audio files have the same sampling rate. This is important for consistency in feature extraction.\n"
      ],
      "metadata": {
        "id": "ERKAV-G3-u3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "\n",
        "def resample_audio(audio_file, target_sr=16000):\n",
        "    y, sr = librosa.load(audio_file, sr=target_sr)\n",
        "    return y, sr\n"
      ],
      "metadata": {
        "id": "XKfQo4vr-wRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizing Volume Levels:\n",
        "Normalizing volume levels ensures that the amplitude of all audio files is within a consistent range."
      ],
      "metadata": {
        "id": "5n0_KN07-5X-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "def normalize_volume(audio_file, target_dBFS=-20):\n",
        "    sound = AudioSegment.from_wav(audio_file)\n",
        "    change_in_dBFS = target_dBFS - sound.dBFS\n",
        "    normalized_sound = sound + change_in_dBFS\n",
        "    return normalized_sound.export(audio_file, format=\"wav\")\n"
      ],
      "metadata": {
        "id": "2NiShowJ-zRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing Noise:\n",
        "Noise removal helps improve the signal-to-noise ratio in the audio, making it easier for the model to extract relevant features."
      ],
      "metadata": {
        "id": "Oja6Jfk0-9nT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.signal as sg\n",
        "\n",
        "def remove_noise(audio_file, window_length=21, threshold=0.05):\n",
        "    y, sr = librosa.load(audio_file)\n",
        "    # Apply a low-pass filter to remove high-frequency noise\n",
        "    y_filtered = sg.medfilt(y, kernel_size=window_length)\n",
        "    # Compute the absolute difference between the original and filtered signals\n",
        "    diff = np.abs(y - y_filtered)\n",
        "    # Use a threshold to identify noisy parts\n",
        "    noisy_indices = np.where(diff > threshold)[0]\n",
        "    # Replace noisy parts with the filtered signal\n",
        "    y_cleaned = np.copy(y)\n",
        "    y_cleaned[noisy_indices] = y_filtered[noisy_indices]\n",
        "    return y_cleaned, sr\n"
      ],
      "metadata": {
        "id": "GGoTCu8J_B6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the path to the folder containing audio files\n",
        "folder_path = \"Gender_WAV\"\n",
        "\n",
        "# Iterate over each audio file in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        # Resample the audio\n",
        "        y_resampled, sr_resampled = resample_audio(audio_file_path)\n",
        "\n",
        "        # Normalize volume levels\n",
        "        normalize_volume(audio_file_path)\n",
        "\n",
        "        # Remove noise\n",
        "        y_cleaned, sr_cleaned = remove_noise(audio_file_path)\n"
      ],
      "metadata": {
        "id": "d79JCLyk_Jk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statistical Features\n",
        "1. Means\n",
        "2. Standard Deviation\n",
        "3. Maximum Value\n",
        "4. Minimum Value"
      ],
      "metadata": {
        "id": "q4Kje8-8Bk8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "# Function to extract MFCC features\n",
        "def extract_mfcc(audio_file):\n",
        "    y, sr = librosa.load(audio_file)\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "    return mfccs.T  # Transpose to have features along the columns\n",
        "\n",
        "# Function to compute statistical features\n",
        "def compute_statistics(features):\n",
        "    mean = np.mean(features, axis=0)\n",
        "    std_dev = np.std(features, axis=0)\n",
        "    min_val = np.min(features, axis=0)\n",
        "    max_val = np.max(features, axis=0)\n",
        "    return mean, std_dev, min_val, max_val\n",
        "\n",
        "# Directory containing audio files\n",
        "data_dir = \"Gender_WAV\"\n",
        "\n",
        "# List to store data\n",
        "file_names = []\n",
        "gender_labels = []\n",
        "mean_features = []\n",
        "std_dev_features = []\n",
        "min_features = []\n",
        "max_features = []\n",
        "\n",
        "# Iterate over each audio file in the directory\n",
        "for filename in os.listdir(data_dir):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file_path = os.path.join(data_dir, filename)\n",
        "\n",
        "        # Extract gender label from file name (assuming file name format: <gender>_<ID>.wav)\n",
        "        gender_label = 1 if \"female\" in filename else 0\n",
        "\n",
        "        # Compute statistical features\n",
        "        y, sr = librosa.load(audio_file_path)\n",
        "        # Extract statistical features directly from the audio\n",
        "        mean, std_dev, min_val, max_val = compute_statistics(y)\n",
        "\n",
        "        # Append data to lists\n",
        "        file_names.append(filename)\n",
        "        gender_labels.append(gender_label)\n",
        "        mean_features.append(mean.tolist())\n",
        "        std_dev_features.append(std_dev.tolist())\n",
        "        min_features.append(min_val.tolist())\n",
        "        max_features.append(max_val.tolist())\n",
        "\n",
        "# Save data to a text file\n",
        "with open(\"audio_data.txt\", \"w\") as file:\n",
        "    file.write(\"Name,Gender,Mean,Std Dev,Min,Max\\n\")\n",
        "    for i in range(len(file_names)):\n",
        "        file.write(f\"{file_names[i]},{gender_labels[i]},{mean_features[i]},{std_dev_features[i]},{min_features[i]},{max_features[i]}\\n\")\n"
      ],
      "metadata": {
        "id": "mb2NC8pTBkG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data from the text file\n",
        "data = np.loadtxt(\"audio_data.txt\", delimiter=\",\", skiprows=1, dtype=str)\n",
        "\n",
        "# Extract features and labels\n",
        "X = data[:, 2:].astype(float)  # Features (mean, std dev, min, max)\n",
        "y = data[:, 1].astype(int)  # Gender labels\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "\n",
        "# Print the shapes of the training and testing sets\n",
        "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZr3b1rNGqZN",
        "outputId": "7a36b8e6-a4fa-45c0-b4c0-b2045386d57c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (60, 4) (60,)\n",
            "Testing set shape: (40, 4) (40,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build logistic regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the testing set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_yU_4P0IPhx",
        "outputId": "f6bf0277-e013-4a45-a0fa-7ed68bd70ff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an expanded hyperparameters grid\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],  # Regularization strength\n",
        "    'solver': ['liblinear', 'lbfgs', 'sag', 'newton-cg'],  # Optimization algorithm\n",
        "    'penalty': ['l2'],  # Regularization penalty compatible with lbfgs, sag, and newton-cg\n",
        "    'max_iter': [100, 200, 300]  # Maximum number of iterations\n",
        "}\n",
        "\n",
        "# Perform grid search cross-validation\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Evaluate the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6riYgvkJf5z",
        "outputId": "043f3a0a-9a1a-41e5-c4bd-ab5c9b5be35b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Predict labels for the testing set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrujyAIcG45k",
        "outputId": "f58283ef-a1d6-4cae-d364-99c2c4f7c69e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "Accuracy: 0.47\n",
            "Precision: 0.70\n",
            "Recall: 0.28\n",
            "F1-Score: 0.40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy: The proportion of correctly classified samples out of the total number of samples. In this case, the accuracy is 0.47, indicating that 47% of the samples were classified correctly.\n",
        "\n",
        "Precision: The proportion of true positive predictions out of all positive predictions made by the model. A precision of 0.70 means that out of all samples predicted as positive by the model, 70% were actually positive.\n",
        "\n",
        "Recall: The proportion of true positive predictions out of all actual positive samples in the dataset. A recall of 0.28 indicates that the model correctly identified 28% of all actual positive samples in the dataset.\n",
        "\n",
        "F1-Score: The harmonic mean of precision and recall, providing a balance between the two metrics. A higher F1-score indicates better balance between precision and recall. In this case, an F1-score of 0.40 reflects the balance between precision and recall."
      ],
      "metadata": {
        "id": "RCt5vdaBHSJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load data from the text file\n",
        "data = np.loadtxt(\"audio_data.txt\", delimiter=\",\", skiprows=1, dtype=str)\n",
        "\n",
        "# Extract features (mean, std dev, max, min) and labels from the data\n",
        "features = data[:, 2:].astype(float)\n",
        "labels = data[:, 1].astype(int)\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the features\n",
        "scaler.fit(features)\n",
        "\n",
        "# Scale features using the fitted scaler\n",
        "scaled_features = scaler.transform(features)\n",
        "\n",
        "# Initialize the logistic regression model\n",
        "model = LogisticRegression(C=0.1, max_iter=100, penalty='l2', solver='lbfgs')\n",
        "\n",
        "# Fit the logistic regression model to the scaled features and labels\n",
        "model.fit(scaled_features, labels)\n",
        "\n",
        "def predict_gender_from_data(data):\n",
        "    # Scale features using the fitted scaler\n",
        "    scaled_data = scaler.transform(data)\n",
        "    # Make predictions using the trained model\n",
        "    predicted_gender = model.predict(scaled_data)\n",
        "    return predicted_gender\n",
        "\n",
        "# Predict gender using the features from the data\n",
        "predicted_genders = predict_gender_from_data(features)\n",
        "\n",
        "# Print the predicted genders\n",
        "for i in range(len(predicted_genders)):\n",
        "    if predicted_genders[i] == 1:\n",
        "        print(f\"Audio {data[i, 0]} is a female.\")\n",
        "    else:\n",
        "        print(f\"Audio {data[i, 0]} is a male.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "SaLPu5LZKTdQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}