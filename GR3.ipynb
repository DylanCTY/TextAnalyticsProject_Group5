{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DylanCTY/TextAnalyticsProject_Group5/blob/main/GR3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl02A6ZEuJtM",
        "outputId": "76aebb94-0f3f-4295-ef4d-5ce750ebee9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ta5_gender'...\n",
            "remote: Enumerating objects: 109, done.\u001b[K\n",
            "remote: Counting objects: 100% (109/109), done.\u001b[K\n",
            "remote: Compressing objects: 100% (108/108), done.\u001b[K\n",
            "remote: Total 109 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (109/109), 6.00 MiB | 14.40 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ktcktc26/ta5_gender.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0SnnVdkuxjM",
        "outputId": "702dc8b5-9c6b-499d-d580-db3da0c3fe9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert M4A TO WAV\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "\n",
        "def convert_m4a_to_wav(m4a_file, wav_file):\n",
        "    sound = AudioSegment.from_file(m4a_file)\n",
        "    sound.export(wav_file, format=\"wav\")\n",
        "\n",
        "def batch_convert_m4a_to_wav(input_folder, output_folder):\n",
        "    # Create output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Get a list of all files in the input folder\n",
        "    files = os.listdir(input_folder)\n",
        "\n",
        "    # Iterate through each file\n",
        "    for file in files:\n",
        "        # Check if the file is an m4a file\n",
        "        if file.endswith(\".m4a\"):\n",
        "            # Construct full paths for input and output files\n",
        "            m4a_path = os.path.join(input_folder, file)\n",
        "            wav_path = os.path.join(output_folder, file.replace(\".m4a\", \".wav\"))\n",
        "\n",
        "            # Convert m4a to wav\n",
        "            print(f\"Converting {m4a_path} to {wav_path}\")\n",
        "            convert_m4a_to_wav(m4a_path, wav_path)\n",
        "\n",
        "# Convert female\n",
        "batch_convert_m4a_to_wav(\"/content/ta5_gender/dataset_gender/Female\", \"/content/ta5_gender/dataset_wav/Female\")\n",
        "# Convert male\n",
        "batch_convert_m4a_to_wav(\"/content/ta5_gender/dataset_gender/Male\", \"/content/ta5_gender/dataset_wav/Male\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6shEelfIuQ_I",
        "outputId": "72a1e3e5-dc10-47ff-9c64-483124244338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting /content/ta5_gender/dataset_gender/Female/76.m4a to /content/ta5_gender/dataset_wav/Female/76.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2268.m4a to /content/ta5_gender/dataset_wav/Female/2268.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2296.m4a to /content/ta5_gender/dataset_wav/Female/2296.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/30.m4a to /content/ta5_gender/dataset_wav/Female/30.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/9.m4a to /content/ta5_gender/dataset_wav/Female/9.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/33.m4a to /content/ta5_gender/dataset_wav/Female/33.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2294.m4a to /content/ta5_gender/dataset_wav/Female/2294.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2271.m4a to /content/ta5_gender/dataset_wav/Female/2271.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2282.m4a to /content/ta5_gender/dataset_wav/Female/2282.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2265.m4a to /content/ta5_gender/dataset_wav/Female/2265.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/26.m4a to /content/ta5_gender/dataset_wav/Female/26.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2304.m4a to /content/ta5_gender/dataset_wav/Female/2304.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/67.m4a to /content/ta5_gender/dataset_wav/Female/67.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2275.m4a to /content/ta5_gender/dataset_wav/Female/2275.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/79.m4a to /content/ta5_gender/dataset_wav/Female/79.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/28.m4a to /content/ta5_gender/dataset_wav/Female/28.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/73.m4a to /content/ta5_gender/dataset_wav/Female/73.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/46.m4a to /content/ta5_gender/dataset_wav/Female/46.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/54.m4a to /content/ta5_gender/dataset_wav/Female/54.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2.m4a to /content/ta5_gender/dataset_wav/Female/2.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2299.m4a to /content/ta5_gender/dataset_wav/Female/2299.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2277.m4a to /content/ta5_gender/dataset_wav/Female/2277.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/62.m4a to /content/ta5_gender/dataset_wav/Female/62.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2269.m4a to /content/ta5_gender/dataset_wav/Female/2269.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/86.m4a to /content/ta5_gender/dataset_wav/Female/86.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2257.m4a to /content/ta5_gender/dataset_wav/Female/2257.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/52.m4a to /content/ta5_gender/dataset_wav/Female/52.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/36.m4a to /content/ta5_gender/dataset_wav/Female/36.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2291.m4a to /content/ta5_gender/dataset_wav/Female/2291.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2295.m4a to /content/ta5_gender/dataset_wav/Female/2295.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2279.m4a to /content/ta5_gender/dataset_wav/Female/2279.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/60.m4a to /content/ta5_gender/dataset_wav/Female/60.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/8.m4a to /content/ta5_gender/dataset_wav/Female/8.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2256.m4a to /content/ta5_gender/dataset_wav/Female/2256.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/16.m4a to /content/ta5_gender/dataset_wav/Female/16.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2303.m4a to /content/ta5_gender/dataset_wav/Female/2303.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2298.m4a to /content/ta5_gender/dataset_wav/Female/2298.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/6.m4a to /content/ta5_gender/dataset_wav/Female/6.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2300.m4a to /content/ta5_gender/dataset_wav/Female/2300.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2258.m4a to /content/ta5_gender/dataset_wav/Female/2258.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2264.m4a to /content/ta5_gender/dataset_wav/Female/2264.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2270.m4a to /content/ta5_gender/dataset_wav/Female/2270.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2292.m4a to /content/ta5_gender/dataset_wav/Female/2292.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/15.m4a to /content/ta5_gender/dataset_wav/Female/15.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2283.m4a to /content/ta5_gender/dataset_wav/Female/2283.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/31.m4a to /content/ta5_gender/dataset_wav/Female/31.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/29.m4a to /content/ta5_gender/dataset_wav/Female/29.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/91.m4a to /content/ta5_gender/dataset_wav/Female/91.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/25.m4a to /content/ta5_gender/dataset_wav/Female/25.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Female/2289.m4a to /content/ta5_gender/dataset_wav/Female/2289.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3613.m4a to /content/ta5_gender/dataset_wav/Male/3613.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/30.m4a to /content/ta5_gender/dataset_wav/Male/30.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/11.m4a to /content/ta5_gender/dataset_wav/Male/11.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/66.m4a to /content/ta5_gender/dataset_wav/Male/66.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3640.m4a to /content/ta5_gender/dataset_wav/Male/3640.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/33.m4a to /content/ta5_gender/dataset_wav/Male/33.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3638.m4a to /content/ta5_gender/dataset_wav/Male/3638.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/19.m4a to /content/ta5_gender/dataset_wav/Male/19.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3622.m4a to /content/ta5_gender/dataset_wav/Male/3622.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/26.m4a to /content/ta5_gender/dataset_wav/Male/26.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3.m4a to /content/ta5_gender/dataset_wav/Male/3.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3652.m4a to /content/ta5_gender/dataset_wav/Male/3652.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3642.m4a to /content/ta5_gender/dataset_wav/Male/3642.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/47.m4a to /content/ta5_gender/dataset_wav/Male/47.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/46.m4a to /content/ta5_gender/dataset_wav/Male/46.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/2.m4a to /content/ta5_gender/dataset_wav/Male/2.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/64.m4a to /content/ta5_gender/dataset_wav/Male/64.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3637.m4a to /content/ta5_gender/dataset_wav/Male/3637.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3665.m4a to /content/ta5_gender/dataset_wav/Male/3665.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/23.m4a to /content/ta5_gender/dataset_wav/Male/23.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3651.m4a to /content/ta5_gender/dataset_wav/Male/3651.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/24.m4a to /content/ta5_gender/dataset_wav/Male/24.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/18.m4a to /content/ta5_gender/dataset_wav/Male/18.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3655.m4a to /content/ta5_gender/dataset_wav/Male/3655.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3632.m4a to /content/ta5_gender/dataset_wav/Male/3632.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/32.m4a to /content/ta5_gender/dataset_wav/Male/32.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3677.m4a to /content/ta5_gender/dataset_wav/Male/3677.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/21.m4a to /content/ta5_gender/dataset_wav/Male/21.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3630.m4a to /content/ta5_gender/dataset_wav/Male/3630.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3635.m4a to /content/ta5_gender/dataset_wav/Male/3635.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3619.m4a to /content/ta5_gender/dataset_wav/Male/3619.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/69.m4a to /content/ta5_gender/dataset_wav/Male/69.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3621.m4a to /content/ta5_gender/dataset_wav/Male/3621.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3671.m4a to /content/ta5_gender/dataset_wav/Male/3671.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3618.m4a to /content/ta5_gender/dataset_wav/Male/3618.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3667.m4a to /content/ta5_gender/dataset_wav/Male/3667.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3658.m4a to /content/ta5_gender/dataset_wav/Male/3658.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/34.m4a to /content/ta5_gender/dataset_wav/Male/34.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/31.m4a to /content/ta5_gender/dataset_wav/Male/31.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/29.m4a to /content/ta5_gender/dataset_wav/Male/29.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3641.m4a to /content/ta5_gender/dataset_wav/Male/3641.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/68.m4a to /content/ta5_gender/dataset_wav/Male/68.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3679.m4a to /content/ta5_gender/dataset_wav/Male/3679.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3676.m4a to /content/ta5_gender/dataset_wav/Male/3676.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/25.m4a to /content/ta5_gender/dataset_wav/Male/25.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/45.m4a to /content/ta5_gender/dataset_wav/Male/45.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/0.m4a to /content/ta5_gender/dataset_wav/Male/0.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3672.m4a to /content/ta5_gender/dataset_wav/Male/3672.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/4.m4a to /content/ta5_gender/dataset_wav/Male/4.wav\n",
            "Converting /content/ta5_gender/dataset_gender/Male/3645.m4a to /content/ta5_gender/dataset_wav/Male/3645.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Build Training Data Set from Female and Male Voices\n",
        "import librosa\n",
        "import pandas as pd\n",
        "\n",
        "def extract_pitch(wav_file):\n",
        "    # Load audio file\n",
        "    audio, sr = librosa.load(wav_file, sr=None)\n",
        "\n",
        "    # Extract pitch information\n",
        "    pitch, mag = librosa.piptrack(y=audio, sr=sr)\n",
        "    pitch = pitch[:, 0]  # Extract the first channel if it's stereo\n",
        "\n",
        "    # Calculate mean, max, min\n",
        "    mean_pitch = pitch.mean()\n",
        "    max_pitch = pitch.max()\n",
        "    min_pitch = pitch.min()\n",
        "\n",
        "    return mean_pitch, max_pitch, min_pitch\n",
        "\n",
        "def build_pitch_data(test_folder):\n",
        "    # Initialize lists to store pitch data\n",
        "    mean_pitches = []\n",
        "    max_pitches = []\n",
        "    min_pitches = []\n",
        "\n",
        "    # Get a list of all files in the input folder\n",
        "    files = os.listdir(test_folder)\n",
        "\n",
        "    # Iterate through each file\n",
        "    for file in files:\n",
        "        # Check if the file is a WAV file\n",
        "        if file.endswith(\".wav\"):\n",
        "            wav_file = os.path.join(test_folder, file)\n",
        "\n",
        "            # Extract pitch from the WAV file\n",
        "            mean_pitch, max_pitch, min_pitch = extract_pitch(wav_file)\n",
        "\n",
        "            # Store pitch data\n",
        "            mean_pitches.append(mean_pitch)\n",
        "            max_pitches.append(max_pitch)\n",
        "            min_pitches.append(min_pitch)\n",
        "\n",
        "  # Create DataFrame\n",
        "    data = {\n",
        "        \"mean_pitch\": mean_pitches,\n",
        "        \"max_pitch\": max_pitches,\n",
        "        \"min_pitch\": min_pitches,\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "# Build Training Data Set\n",
        "female_data = \"/content/ta5_gender/dataset_wav/Female\"\n",
        "male_data = \"/content/ta5_gender/dataset_wav/Male\"\n",
        "\n",
        "df_f = build_pitch_data(female_data)\n",
        "df_f['gender'] = 1\n",
        "df_m = build_pitch_data(male_data)\n",
        "df_m['gender'] = 0\n",
        "\n",
        "df = pd.concat([df_f, df_m])\n",
        "\n",
        "df.tail()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "WwRW6vUevGdQ",
        "outputId": "b26ff237-f11e-4162-f9b6-d159023195c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    mean_pitch    max_pitch  min_pitch  gender\n",
              "45    8.109263  1742.610596        0.0       0\n",
              "46   12.164597  1352.468628        0.0       0\n",
              "47   20.253422  1824.171997        0.0       0\n",
              "48    2.383928   702.612915        0.0       0\n",
              "49   83.146263  3888.390625        0.0       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a611b328-45bc-448f-914b-e0083314840f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_pitch</th>\n",
              "      <th>max_pitch</th>\n",
              "      <th>min_pitch</th>\n",
              "      <th>gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>8.109263</td>\n",
              "      <td>1742.610596</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>12.164597</td>\n",
              "      <td>1352.468628</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>20.253422</td>\n",
              "      <td>1824.171997</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>2.383928</td>\n",
              "      <td>702.612915</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>83.146263</td>\n",
              "      <td>3888.390625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a611b328-45bc-448f-914b-e0083314840f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a611b328-45bc-448f-914b-e0083314840f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a611b328-45bc-448f-914b-e0083314840f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8312e2dd-4598-4452-9f6b-a1f1497d6063\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8312e2dd-4598-4452-9f6b-a1f1497d6063')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8312e2dd-4598-4452-9f6b-a1f1497d6063 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"mean_pitch\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          12.164596557617188,\n          83.1462631225586,\n          20.253421783447266\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max_pitch\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1352.4686279296875,\n          3888.390625,\n          1824.1719970703125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min_pitch\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANoQEKwZTcch",
        "outputId": "57f7df16-6bb6-4745-a850-5ebcf73f1844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Model\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import metrics\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def parameter_tuning_svm(input_df):\n",
        "    x = input_df[['mean_pitch' , 'max_pitch', 'min_pitch']].values\n",
        "    y = input_df['gender'].values\n",
        "   #svc = SVC(kernel='linear')\n",
        "\n",
        "    #segmenting data set and cross validation\n",
        "    training, testing, training_result, testing_result = train_test_split(x, y, test_size=0.4, random_state=1)\n",
        "    # scores = cross_val_score(svc, training, training_result, cv=10, scoring='accuracy')\n",
        "    # print scores.mean()\n",
        "\n",
        "    #Tuning C value\n",
        "    c_vals = list(range(1,5))\n",
        "    accuracy_vals = []\n",
        "    for val in c_vals:\n",
        "        svc = SVC(kernel='linear', C=val)\n",
        "        scores = cross_val_score(svc, training, training_result, cv=10, scoring='accuracy')\n",
        "        accuracy_vals.append(scores.mean())\n",
        "\n",
        "    # plt.plot(c_vals, accuracy_vals)\n",
        "    # plt.xticks(np.arange(0,30,2))\n",
        "    # plt.xlabel('C values')\n",
        "    # plt.ylabel('Mean Accuracies')\n",
        "    # plt.show()\n",
        "\n",
        "    optimal_cval = c_vals[accuracy_vals.index(max(accuracy_vals))]\n",
        "    print(optimal_cval)\n",
        "\n",
        "    #gamma value tuning\n",
        "    gamma_vals = [0.00001,0.0001,0.001,0.01,0.1]\n",
        "    accuracy_vals = []\n",
        "    for g in gamma_vals:\n",
        "        svc = SVC(kernel='linear', C=optimal_cval, gamma=g)\n",
        "        scores = cross_val_score(svc, training, training_result, cv=10, scoring='accuracy')\n",
        "        accuracy_vals.append(scores.mean())\n",
        "\n",
        "    optimal_gamma = gamma_vals[accuracy_vals.index(max(accuracy_vals))]\n",
        "    print(optimal_gamma)\n",
        "\n",
        "    svc = SVC(kernel='linear', C=optimal_cval, gamma=optimal_gamma)\n",
        "    svc.fit(training, training_result)\n",
        "    testing_predict = svc.predict(testing)\n",
        "    print(metrics.accuracy_score(testing_predict, testing_result))\n",
        "\n",
        "    svc = SVC(kernel='linear', C=optimal_cval, gamma=optimal_gamma)\n",
        "    svc.fit(x,y)\n",
        "    return svc"
      ],
      "metadata": {
        "id": "a9T_uX9XyGlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Model\n",
        "tuned_svm = parameter_tuning_svm(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sl_qtw641wbE",
        "outputId": "34c59306-c3e9-439a-e158-c6d11593fea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1e-05\n",
            "0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Model (to cut time)\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import metrics\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "\n",
        "x = df[['mean_pitch' , 'max_pitch', 'min_pitch']].values\n",
        "y = df['gender'].values\n",
        "\n",
        "#segmenting data set and cross validation\n",
        "training, testing, training_result, testing_result = train_test_split(x, y, test_size=0.4, random_state=1)\n",
        "svc = SVC(kernel='linear', C=1, gamma=0.01)\n",
        "svc.fit(training, training_result)\n",
        "testing_predict = svc.predict(testing)\n",
        "print(metrics.accuracy_score(testing_predict, testing_result))\n",
        "\n",
        "tuned_svm = svc\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncKn0d7tGEi2",
        "outputId": "f9d5cea2-5b15-45fe-f96c-eae79f7b71b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "test_folder = \"/content/test\"\n",
        "test_wav = \"/content/test_wav\"\n",
        "\n",
        "# Convert m4a to wav\n",
        "batch_convert_m4a_to_wav(test_folder, test_wav)\n",
        "\n",
        "# Prediction\n",
        "df_test = build_pitch_data(test_wav)\n",
        "df_test.head()\n",
        "\n",
        "prediction = []\n",
        "for i in range(len(df_test)):\n",
        "  values = np.array(df_test[['mean_pitch' , 'max_pitch', 'min_pitch']].iloc[i], dtype=np.float64)\n",
        "  values = values.reshape(1, -1)\n",
        "  result = tuned_svm.predict(values)\n",
        "  if result == 0:\n",
        "    prediction.append(\"female\")\n",
        "  else:\n",
        "    prediction.append(\"male\")\n",
        "\n",
        "x = 0\n",
        "files = os.listdir(test_wav)\n",
        "\n",
        "for file in files:\n",
        "    # Check if the file is a WAV file\n",
        "    if file.endswith(\".wav\"):\n",
        "    # Construct full paths for test files\n",
        "        test_path = os.path.join(test_wav, file)\n",
        "        file_name = os.path.basename(test_path)\n",
        "        print(f\"File {file_name} is {prediction[x]}\")\n",
        "        x = x+1\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dz0io09Q25cT",
        "outputId": "89bd8aac-148e-425b-d9bf-c15f979e53be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting /content/test/female_test.m4a to /content/test_wav/female_test.wav\n",
            "Converting /content/test/male_test.m4a to /content/test_wav/male_test.wav\n",
            "File female_test.wav is female\n",
            "File male_test.wav is female\n",
            "['female', 'female']\n"
          ]
        }
      ]
    }
  ]
}